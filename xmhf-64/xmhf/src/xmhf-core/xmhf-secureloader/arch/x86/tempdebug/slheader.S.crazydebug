// secure loader support routines
// authors: amit vasudevan (amitvasudevan@acm.org) and jonmccune@gmail.com

#include <target.h>
#include <msr.h>
#include <svm.h>
#include <processor.h>

.macro OUT2VGA
    movl %ecx, %eax
    rol $8, %eax
    call dumpal
    movl %ecx, %eax
    rol $16, %eax
    call dumpal
    movl %ecx, %eax
    rol $24, %eax
    call dumpal
    movl %ecx, %eax
    call dumpal
    call aspace 
.endm

              
//our C main
.extern slmain
.extern serial_putc

/* The first 3 pages of the SL serve different purposes depending on
   whether the system has an AMD or Intel CPU.  On an AMD system, the
   first four bytes of the first page comprise the SLB Header.  The
   remainder goes to waste (3*4K-4B).

   On Intel, these first three pages are used as the MLE Page Tables.
   These are constructed in software with the txt.c:build_mle_pagetable()
   function.  The AMD header will be clobbered in the process.

   These 3 pages are placed at the very beginning of the SL (byte 0)
   by our linker script.  Our SL is always padded to 64K in size
   regardless of the actual size of the code or data.  The linker
   relocation base for our SL is always 0.  The SL must be position-
   independent. */
              
.section .sl_header
    .global _mle_page_table_start
    _mle_page_table_start:
              
	.global _sl_header
	_sl_header:         // AMD-specific header format for Secure Loader Block (SLB)
	.word _sl_start 	//SL entry point relative to header (bits 0-15)
	.word 0xFFFF  		//SL size including the header (bits 16-32)
									  //i.e, 0 through 65535 inclusive = 64K


    // Three 4K pages to hold the "MLE page tables" for an Intel-specific
    // DRTM using GETSEC[SENTER].  See 2.2.4.1 in Intel MLE
    // Developer's Guide (Dec. 2009 revision).
    .align 4096      // remainder of first page
    .fill 4096, 1, 0 // second page
    .fill 4096, 1, 0 // third page
    .global _mle_page_table_end
    _mle_page_table_end:


.section .text
    // Make room for MLE header at beginning
    .global _mle_hdr
    _mle_hdr:
    .fill TEMPORARY_MAX_MLE_HEADER_SIZE, 1, 0x90 ///XXX TODO just a guess; should really be sizeof(mle_hdr_t)
              
              
	.global _sl_start
	_sl_start:
              
    // LET'S FIGURE OUT REG VALUES UPON ENTRY HERE (ON INTEL)
    pushl %eax
    pushl %ebx
    pushl %ecx
    pushl %edx
    pushl %edi
    pushl %esi
    pushl %esp
    pushl %ebp
              
    //save EAX, for AMD and the stub SENTER DRTM this contains the
	//64K aligned physical memory address where the sl was loaded 
//	movl %eax, %ebp
    // AMD leaves base addr in EAX, but Intel does not.  Since both CS and SS
    // are valid, read and align EIP to discover base addr
    call 1f
1:  popl %eax // put EIP into EAX
    andl $0xffff0000, %eax // 64K-align
    movl %eax, %ebp
              
    /*** DELAY OF ABOUT 15 seconds ***/              
//     movl $0x0, %edx
//     movl $0x5, %ecx // this line affects delay
//     outer: movl $0x0, %eax
//     movl $0xffffffff, %ebx
//     inner: addl $0x1, %eax
//     cmp %ebx, %eax
//     jne inner
//     addl $0x1, %edx
//     cmp %ecx, %edx
//     jne outer
	
	//other assumptions: common to both Intel and AMD (?)
	//CS and SS as flat code and data segment selectors
	//EFLAGS_IF=0 (GIF=0 on AMD) so we are running with no interruptions
	//CR0.PG= 0 i.e, paging is off
	

	//determine processor type, we need to perform some low-level inits
	//after DRTM depending on the processor. for example on the AMD CPUs
	//we need to clear R_INIT, DIS_A20M and CR_DPD in VM_CR_MSR
sl_cpu_vendor:	
		xor	%eax, %eax
		cpuid		
		cmpl $(INTEL_STRING_DWORD1), %ebx
		jne sl_cpu_vendor_notintel
		cmpl $(INTEL_STRING_DWORD2), %edx
		jne sl_cpu_vendor_notintel
		cmpl $(INTEL_STRING_DWORD3), %ecx
		jne sl_cpu_vendor_notintel
		movl $(CPU_VENDOR_INTEL), %esi
		jmp sl_cpu_vendor_done
	sl_cpu_vendor_notintel:
		cmpl $(AMD_STRING_DWORD1), %ebx
		jne sl_cpu_vendor_unknown
		cmpl $(AMD_STRING_DWORD2), %edx
		jne sl_cpu_vendor_unknown
		cmpl $(AMD_STRING_DWORD3), %ecx
		jne sl_cpu_vendor_unknown
		movl $(CPU_VENDOR_AMD), %esi
		jmp sl_cpu_vendor_done
	sl_cpu_vendor_unknown:
		//this should never happen, but we have a fallback in case
		ud2
		hlt		
	sl_cpu_vendor_done:		
	//%esi contains vendor CPU_VENDOR_INTEL or CPU_VENDOR_AMD

	//if AMD CPU enable a few things that SKINIT disables
	//enable HDT debugging, also clear R_INIT and DIS_A20M
    //XXX TODO Disable HDT debugging; represents a security vulnerability
	cmpl $(CPU_VENDOR_AMD), %esi
	jne sl_cpu_intel
sl_cpu_amd:   
	movl $(VM_CR_MSR), %ecx
	rdmsr
	andl $(~(1<<VM_CR_DPD)), %eax
	andl $(~(1<<VM_CR_R_INIT)), %eax
	andl $(~(1<<VM_CR_DIS_A20M)), %eax
	wrmsr
    jmp sl_cpu_common

sl_cpu_intel:
    jmp sl_cpu_common

	//common code from now on						  
sl_cpu_common:						  
	//from here on we use EBP as base and variable accesses will be as offsets
	//from _sl_header for position independence
	
	//setup GDT so that CS:base=sl base, limit=64K, type=code
	//DS,SS,ES: base=sl base, limit=64K, type=data
	//FS and GS: base=0, limit=4G, type=data (FLAT)

		//grab offset of sl_gdt_start
		movl $(sl_gdt_start), %ebx	

		movl %ebp, %eax          	//eax = sl base address
		movl %ebp, %ecx				//ecx = sl base address
		andl $0xFF000000, %eax		//eax = bits 24-31 of sl base address
		andl $0x00FF0000, %ecx		//ecx = bits 16-23 of sl base address
		shrl $16, %ecx				//bits 0-7 of ecx = bits 16-23 of sl base address	
		orl %ecx, %eax				//bits 0-7 of eax = bits 16-23 of sl base address
									//bits 24-31 of eax = bits 24-31 of sl base address
									//eax is now in accordance with the high 32-bits
									//of a segment descriptor 

        // EAX now contains a mask that can be ORed against other addresses
        // It contains [byte 3] [0] [0] [byte 2] of a segment descriptor's base address
       
		//get high 32-bits of 64-bit GDT entry for selector 0x08 (code)
		//and update it with the base address of the sl
		movl %cs:12(%ebp, %ebx), %esi // 12 = 8-byte null descriptor + skip 4 low bytes
        andl  $0x00FFFF00, %esi // mask off any existing base addr bits that are set
		orl %eax, %esi         // OR in base addr bits computed in EAX
		//AMDmovl %esi, %ss:12(%ebp, %ebx) // put the updated entry back in the GDT
		movl %esi, %ds:12(%ebp, %ebx) // put the updated entry back in the GDT
              
		//get high 32-bits of 64-bit GDT entry for selector 0x10 (data)
		//and update it with the base address of the sl
		movl %cs:20(%ebp, %ebx), %esi
		andl $0x00FFFF00, %esi
		orl %eax, %esi
		//AMDmovl %esi, %ss:20(%ebp, %ebx) 
		movl %esi, %ds:20(%ebp, %ebx) 
		

	//fixup linear address of GDT using sl load-base
	movl $(sl_gdt), %ebx	
	//AMDaddl %ebp, %ss:2(%ebp, %ebx)
	addl %ebp, %ds:2(%ebp, %ebx)

	//load sl gdt	
	lgdt %cs:(%ebp,%ebx)

	movl $(sl_gdt), %ebx
              
    // VGA debugging? %ss modifier doesn't work correctly for VGA output
    //goal: dump GDT to screen in hex
    movl $0x0, %esi // all-time VGA offset buffer

    call 1f   // 1. dump EIP
1:  pop %ecx
    OUT2VGA
    movl $0xdeadbeef, %ecx // 2. useful to help w/ reversing, endian issues, etc
    OUT2VGA
    movl %esp, %ecx // 3. where is the stack?
    OUT2VGA
    movl %ebp, %ecx // 4. print what we're using as base address
    OUT2VGA
    movl %ebx, %ecx // 5. print what we're using as ebx offset
    OUT2VGA
    leal (%ebp, %ebx), %ecx // 6. addr of base of stuff we want to dump
    OUT2VGA

    // GDT pseudo-descriptor          
    movl $0, %ecx
    movw %cs:(%ebp, %ebx), %cx // 7. word of GDT pseudo-descriptor
    OUT2VGA
    movl %cs:2(%ebp, %ebx), %ecx // 8. long of GDT pseudo-descriptor
    OUT2VGA
              
    // GDT itself
    movl  $(sl_gdt_start), %ebx
    movl %cs:(%ebp, %ebx), %ecx // 9. 
    OUT2VGA
    movl %cs:4(%ebp, %ebx), %ecx // 10.
    OUT2VGA
    movl %cs:8(%ebp, %ebx), %ecx // 11.
    OUT2VGA
    movl %cs:12(%ebp, %ebx), %ecx // 12.
    OUT2VGA
    movl %cs:16(%ebp, %ebx), %ecx // 13.
    OUT2VGA
    movl %cs:20(%ebp, %ebx), %ecx // 14.
    OUT2VGA
    movl %cs:24(%ebp, %ebx), %ecx // 15.
    OUT2VGA
    movl %cs:28(%ebp, %ebx), %ecx // 16.
    OUT2VGA

    popl %ecx              // 17
    OUT2VGA
    popl %ecx              // 18
    OUT2VGA
    popl %ecx              // 19
    OUT2VGA
    popl %ecx              // 20
    OUT2VGA
    popl %ecx              // 21
    OUT2VGA
    popl %ecx              // 22
    OUT2VGA
    popl %ecx              // 23
    OUT2VGA
    popl %ecx              // 24
    OUT2VGA
//1:            jmp 1b // HANG FOR NOW; WE WANT TO SEE SCREEN
    

              
	//far jump to reload %cs
	jmpl $0x08, $(sl_startnew) // XXX PROBLEM HERE (more likely, problem with GDT?)

	//we start here with our new GDT CS selector
sl_startnew:
	//load new segment selectors for DS, SS and ES
	movw $0x10, %ax
	movw %ax, %ds
	movw %ax, %es
	movw %ax, %ss

	//load 4G flat selectors to FS and GS
	movw $0x18, %ax
	movw %ax, %fs
	movw %ax, %gs

	//setup ESP to top of 64K
	movl $0x10000, %esp	
              
	pushl %ebp
	call slmain
	
  //we should never get here
	spinforever:
		jmp spinforever
	hlt							  

//-- DEBUG STUFF -------------------------------
aspace:
    movb $0x20, 0xb8000(%esi)
    movb $7, 0xb8001(%esi)              
    addl $2, %esi // next character location on screen
    ret
              
dumpal:      
    call  reg2hex
    movb %ah, 0xb8000(%esi) // output ascii char to VGA RAM
    movb $7, 0xb8001(%esi) // white on black
    addl $2, %esi // next character location on screen
    movb %al, 0xb8000(%esi) // output ascii char to VGA RAM
    movb $7, 0xb8001(%esi) // white on black
    addl $2, %esi // next character location on screen
    ret

reg2hex:      //    convert byte in al to ascii equivalent in AX, e.g., 0x12 -> 0x3132
    mov %al, %ah // duplicate byte
    and $0x0f, %al // keep only low nibble
    shr $4, %ah  // shift right to access high nibble
    and $0x0f, %ah // keep only low nibble
low:
    cmp $0xa, %al
    jge lowletter
lowdigit:
    add $0x30, %al // convert digit from numerical value to ASCII
    jmp high
lowletter:
    add $0x57, %al // convert digit from numerical value to ASCII

high:
    cmp $0xa, %ah
    jge highletter
highdigit:
    add $0x30, %ah
    ret
highletter:
    add $0x57, %ah // - 0xa + 'a'
    ret

nomoredebug:
    jmp nomoredebug
//-- END DEBUG STUFF ---------------------------

              
.section .data
	
	//the secure loader GDT
	sl_gdt:
	.word	sl_gdt_end - sl_gdt_start + 1	 // XXX WAS PREVIOUSLY -1 !!!
	.long	sl_gdt_start							//this will be fixed up to sl load-base
	.align	16
	sl_gdt_start:
	.quad	0x0000000000000000				//0x00: NULL selector	
//	.quad	0x00409a000000ffff				//0x08: 64K CODE selector	
//	.quad	0x004092000000ffff				//0x10: 64K DATA selector	
	.quad	0x00cf9a000000ffff				//0x08: 4G CODE selector with sl load-base	
	.quad	0x00cf92000000ffff				//0x10: 4G DATA selector with sl load-base	
	.quad   0x00cf92000000ffff				//0x18: 4G DATA selector with zero base
	.quad	0x0000000000000000				//0x20: NULL selector	
	sl_gdt_end:

	
//sl stack, this is just a placeholder and ensures that the linker
//actually "allocates" the stack up until 0x10000
.section .sl_stack
	.fill 4096, 1, 0  	
	
//this section is the input parameter section for the secure loader
//parameters from "init" are placed here. ordering of the variables
//MUST match that in include/target.h
//this section is currently a pagesize in length and resides above
//the 64K sl image
//.section .sl_params

//	.global slpb_buffer
//	slpb_buffer:
//	.long	SL_PARAMETER_BLOCK_MAGIC				//magic		
//	.long	0																//hashSL
//	.long 0																//errorHandler
//	.long 0																//isEarlyInit
//	.long 0																//numE820Entries
//	.fill	(SIZE_STRUCT_GRUBE820 * MAX_E820_ENTRIES), 1, 0	//grub E820 map buffer
//	.long	0																//numCPUEntries
//	.fill (SIZE_STRUCT_PCPU * MAX_PCPU_ENTRIES), 1, 0	//cpu table buffer
//	.long 0																//size of the runtime image		
//	.long 0																//guest OS boot module base
//	.long 0																//guest OS boot module size
